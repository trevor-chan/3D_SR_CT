{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import click\n",
    "import torch\n",
    "import dnnlib\n",
    "from torch_utils import distributed as dist\n",
    "from training import training_loop\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import h5py\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "sys.path.insert(0, '/Users/amyfang/Developer/3D_SR_CT')\n",
    "import augmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchDataset(Dataset):\n",
    "    def __init__(self, hr_dir, if_translation=True, if_rotation=True, if_flip=True, if_downsample=True, flip_prob=0.5, tgt_patch_size=(48, 48, 48), curr_patch_size=(64, 64, 64)):\n",
    "        self.hr_dir = hr_dir\n",
    "        # store full patch paths\n",
    "        self.hr_paths = []\n",
    "        # store corresponding image names\n",
    "        self.hr_img_names = []\n",
    "\n",
    "        for image_folder in os.listdir(hr_dir):\n",
    "            image_path = os.path.join(hr_dir, image_folder)\n",
    "\n",
    "            # Ensure it's a directory\n",
    "            if os.path.isdir(image_path):\n",
    "                for patch in os.listdir(image_path):\n",
    "                    patch_path = os.path.join(image_path, patch)\n",
    "\n",
    "                    if os.path.isfile(patch_path):\n",
    "                        self.hr_paths.append(patch_path)\n",
    "                        self.hr_img_names.append(image_folder)\n",
    "        \n",
    "        # augmentation args\n",
    "        self.translation = if_translation\n",
    "        self.rotation = if_rotation\n",
    "        self.flip = if_flip\n",
    "        self.downsample = if_downsample\n",
    "        self.flip_prob = flip_prob\n",
    "        self.tgt_patch_size = tgt_patch_size\n",
    "        self.curr_patch_size = curr_patch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hr_paths)\n",
    "\n",
    "    def augment(self, hr_patch):\n",
    "        aug_patch = hr_patch\n",
    "        if self.translation:\n",
    "            aug_patch = augmentation.translation(aug_patch, self.tgt_patch_size, self.curr_patch_size)\n",
    "        if self.rotation:\n",
    "            aug_patch = augmentation.rotation(aug_patch)\n",
    "        if self.flip:\n",
    "            aug_patch = augmentation.flip(aug_patch, self.flip_prob)\n",
    "        if self.downsample:\n",
    "            aug_patch = augmentation.downsample(aug_patch)\n",
    "        return aug_patch\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        hr_patch = np.load(self.hr_paths[index])\n",
    "        aug_patch = self.augment(hr_patch)\n",
    "        \n",
    "        return torch.tensor(hr_patch, dtype = torch.float32), torch.tensor(aug_patch, dtype = torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/amyfang/Desktop/PennMed Lab/data\n"
     ]
    }
   ],
   "source": [
    "# read patches from patch folder\n",
    "# Change this: '/Users/amyfang/Desktop/PennMed Lab/patches 2'\n",
    "directory = \"/Users/amyfang/Desktop/PennMed Lab/data\"\n",
    "print(directory)\n",
    "train_data = PatchDataset(hr_dir = directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 100\n",
      "chosen_axis:  (0, 1)\n",
      "axis:  0\n",
      "scale:  3\n",
      "Sample HR shape: torch.Size([64, 64, 64])\n",
      "Sample LR shape: torch.Size([48, 48, 48])\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset length:\", len(train_data))\n",
    "sample_hr, sample_lr = train_data[0]\n",
    "print(\"Sample HR shape:\", sample_hr.shape)\n",
    "print(\"Sample LR shape:\", sample_lr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7717974a40>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hr_np = sample_hr.numpy()\n",
    "\n",
    "# Pick the middle slice along the depth dimension\n",
    "d_hr = hr_np.shape[0] // 2\n",
    "hr_slice = hr_np[d_hr, :, :]\n",
    "\n",
    "plt.imshow(hr_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Input tensor: 1 * 64 * 64 * 64 -> 32\n",
    "- Add cropping function in Dataset: hr\n",
    "- Only use hr. (0:32 voxels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chosen_axis:  (0, 2)\n",
      "axis:  1\n",
      "scale:  4\n",
      "chosen_axis:  (0, 2)\n",
      "axis:  0\n",
      "scale:  5\n",
      "chosen_axis:  (1, 2)\n",
      "axis:  1\n",
      "scale:  5\n",
      "chosen_axis:  (0, 1)\n",
      "axis:  1\n",
      "scale:  5\n",
      "chosen_axis:  (0, 1)\n",
      "scale:  3\n",
      "chosen_axis:  (0, 1)\n",
      "axis:  0\n",
      "scale:  3\n",
      "chosen_axis:  (0, 2)\n",
      "axis:  1\n",
      "scale:  5\n",
      "chosen_axis:  (0, 1)\n",
      "scale:  1\n",
      "chosen_axis:  (0, 1)\n",
      "scale:  3\n",
      "chosen_axis:  (0, 2)\n",
      "scale:  1\n",
      "chosen_axis:  (0, 2)\n",
      "axis:  2\n",
      "scale:  2\n",
      "chosen_axis:  (0, 2)\n",
      "scale:  3\n",
      "chosen_axis:  (1, 2)\n",
      "axis:  0\n",
      "scale:  2\n",
      "chosen_axis:  (0, 2)\n",
      "scale:  1\n",
      "chosen_axis:  (1, 2)\n",
      "scale:  4\n",
      "chosen_axis:  (0, 1)\n",
      "axis:  2\n",
      "scale:  3\n",
      "chosen_axis:  (1, 2)\n",
      "scale:  1\n",
      "chosen_axis:  (0, 2)\n",
      "scale:  3\n",
      "chosen_axis:  (1, 2)\n",
      "axis:  1\n",
      "scale:  5\n",
      "chosen_axis:  (0, 2)\n",
      "scale:  1\n",
      "chosen_axis:  (0, 2)\n",
      "axis:  1\n",
      "scale:  3\n",
      "chosen_axis:  (1, 2)\n",
      "scale:  5\n",
      "chosen_axis:  (0, 1)\n",
      "axis:  2\n",
      "scale:  2\n",
      "chosen_axis:  (0, 1)\n",
      "scale:  1\n",
      "chosen_axis:  (0, 1)\n",
      "axis:  0\n",
      "scale:  4\n",
      "chosen_axis:  (0, 1)\n",
      "scale:  2\n",
      "chosen_axis:  (1, 2)\n",
      "scale:  4\n",
      "chosen_axis:  (0, 2)\n",
      "axis:  0\n",
      "scale:  4\n",
      "chosen_axis:  (0, 2)\n",
      "scale:  3\n",
      "chosen_axis:  (0, 2)\n",
      "scale:  3\n",
      "chosen_axis:  (0, 2)\n",
      "axis:  0\n",
      "scale:  1\n",
      "chosen_axis:  (0, 2)\n",
      "axis:  0\n",
      "scale:  5\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [48, 48, 48] at entry 0 and [50, 50, 50] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# inputs: BxC*H*W tensor, where C is channels, H and W are height and width of the patch\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# labels: Bx0 tensor (if no labels are used) or Bx1 tensor (if image names are used as labels)\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInput shape: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, Label shape: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/SuperResolution_CT_Project/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/envs/SuperResolution_CT_Project/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/SuperResolution_CT_Project/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/SuperResolution_CT_Project/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:398\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    338\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/SuperResolution_CT_Project/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:212\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    208\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 212\u001b[0m         \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed\n\u001b[1;32m    214\u001b[0m     ]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/SuperResolution_CT_Project/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:155\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/anaconda3/envs/SuperResolution_CT_Project/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py:272\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    270\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    271\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 272\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [48, 48, 48] at entry 0 and [50, 50, 50] at entry 1"
     ]
    }
   ],
   "source": [
    "for inputs, labels in dataloader:\n",
    "    # inputs: BxC*H*W tensor, where C is channels, H and W are height and width of the patch\n",
    "    # labels: Bx0 tensor (if no labels are used) or Bx1 tensor (if image names are used as labels)\n",
    "    print(f'Input shape: {inputs.shape}, Label shape: {labels.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on HR patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a model\n",
    "# Copyright (c) 2024, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
    "#\n",
    "# This work is licensed under a Creative Commons\n",
    "# Attribution-NonCommercial-ShareAlike 4.0 International License.\n",
    "# You should have received a copy of the license along with this\n",
    "# work. If not, see http://creativecommons.org/licenses/by-nc-sa/4.0/\n",
    "\n",
    "\"\"\"Main training loop.\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import pickle\n",
    "import psutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import dnnlib\n",
    "from torch_utils import distributed as dist\n",
    "from torch_utils import training_stats\n",
    "from torch_utils import persistence\n",
    "from torch_utils import misc\n",
    "import shutil\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# Uncertainty-based loss function (Equations 14,15,16,21) proposed in the\n",
    "# paper \"Analyzing and Improving the Training Dynamics of Diffusion Models\".\n",
    "\n",
    "# @persistence.persistent_class\n",
    "class EDM2Loss:\n",
    "    def __init__(self, P_mean=-0.4, P_std=1.0, sigma_data=0.5):\n",
    "        self.P_mean = P_mean\n",
    "        self.P_std = P_std\n",
    "        self.sigma_data = sigma_data\n",
    "\n",
    "    def __call__(self, net, images, labels=None):\n",
    "        rnd_normal = torch.randn([images.shape[0], 1, 1, 1, 1], device=images.device)\n",
    "        sigma = (rnd_normal * self.P_std + self.P_mean).exp()\n",
    "        weight = (sigma ** 2 + self.sigma_data ** 2) / (sigma * self.sigma_data) ** 2\n",
    "        noise = torch.randn_like(images) * sigma\n",
    "        denoised, logvar = net(images + noise, sigma, labels, return_logvar=True)\n",
    "        loss = (weight / logvar.exp()) * ((denoised - images) ** 2) + logvar\n",
    "        return loss\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# Learning rate decay schedule used in the paper \"Analyzing and Improving\n",
    "# the Training Dynamics of Diffusion Models\".\n",
    "\n",
    "def learning_rate_schedule(cur_nimg, batch_size, ref_lr=100e-4, ref_batches=70e3, rampup_Mimg=10):\n",
    "    lr = ref_lr\n",
    "    if ref_batches > 0:\n",
    "        lr /= np.sqrt(max(cur_nimg / (ref_batches * batch_size), 1))\n",
    "    if rampup_Mimg > 0:\n",
    "        lr *= min(cur_nimg / (rampup_Mimg * 1e6), 1)\n",
    "    return lr\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "# EDM sampler from the paper\n",
    "# \"Elucidating the Design Space of Diffusion-Based Generative Models\",\n",
    "# extended to support classifier-free guidance.\n",
    "\n",
    "def edm_sampler(\n",
    "    net, noise, labels=None, gnet=None,\n",
    "    num_steps=32, sigma_min=0.002, sigma_max=80, rho=7, guidance=1,\n",
    "    S_churn=0, S_min=0, S_max=float('inf'), S_noise=1,\n",
    "    dtype=torch.float32, randn_like=torch.randn_like,\n",
    "):\n",
    "    # Guided denoiser.\n",
    "    def denoise(x, t):\n",
    "        Dx = net(x, t, labels).to(dtype)\n",
    "        if guidance == 1:\n",
    "            return Dx\n",
    "        ref_Dx = gnet(x, t).to(dtype)\n",
    "        return ref_Dx.lerp(Dx, guidance)\n",
    "\n",
    "    # Time step discretization.\n",
    "    step_indices = torch.arange(num_steps, dtype=dtype, device=noise.device)\n",
    "    t_steps = (sigma_max ** (1 / rho) + step_indices / (num_steps - 1) * (sigma_min ** (1 / rho) - sigma_max ** (1 / rho))) ** rho\n",
    "    t_steps = torch.cat([t_steps, torch.zeros_like(t_steps[:1])]) # t_N = 0\n",
    "\n",
    "    # Main sampling loop.\n",
    "    x_next = noise.to(dtype) * t_steps[0]\n",
    "    for i, (t_cur, t_next) in enumerate(zip(t_steps[:-1], t_steps[1:])): # 0, ..., N-1\n",
    "        x_cur = x_next\n",
    "\n",
    "        # Increase noise temporarily.\n",
    "        if S_churn > 0 and S_min <= t_cur <= S_max:\n",
    "            gamma = min(S_churn / num_steps, np.sqrt(2) - 1)\n",
    "            t_hat = t_cur + gamma * t_cur\n",
    "            x_hat = x_cur + (t_hat ** 2 - t_cur ** 2).sqrt() * S_noise * randn_like(x_cur)\n",
    "        else:\n",
    "            t_hat = t_cur\n",
    "            x_hat = x_cur\n",
    "\n",
    "        # Euler step.\n",
    "        d_cur = (x_hat - denoise(x_hat, t_hat)) / t_hat\n",
    "        x_next = x_hat + (t_next - t_hat) * d_cur\n",
    "\n",
    "        # Apply 2nd order correction.\n",
    "        if i < num_steps - 1:\n",
    "            d_prime = (x_next - denoise(x_next, t_next)) / t_next\n",
    "            x_next = x_hat + (t_next - t_hat) * (0.5 * d_cur + 0.5 * d_prime)\n",
    "\n",
    "    return x_next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = EDM2Loss(P_mean=-0.4, P_std=1.0, sigma_data=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../experiments/hr_patches', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_kwargs      = None\n",
    "data_loader_kwargs  = dict(class_name='torch.utils.data.DataLoader', pin_memory=True, num_workers=2, prefetch_factor=2)\n",
    "network_kwargs      = dict(class_name='training.networks_edm2.Precond')\n",
    "loss_kwargs         = dict(class_name='training.training_loop.EDM2Loss')\n",
    "optimizer_kwargs    = dict(class_name='torch.optim.Adam', betas=(0.9, 0.99))\n",
    "lr_kwargs           = dict(func_name='training.training_loop.learning_rate_schedule')\n",
    "ema_kwargs          = dict(class_name='training.phema.PowerFunctionEMA')\n",
    "\n",
    "run_dir             = '../experiments/hr_patches'      # Output directory.\n",
    "seed                = 0        # Global random seed.\n",
    "batch_size          = 16        # Total batch size for one training iteration.\n",
    "batch_gpu           = None     # Limit batch size per GPU. None = no limit.\n",
    "total_nimg          = 8<<30    # Train for a total of N training images.\n",
    "slice_nimg          = None     # Train for a maximum of N training images in one invocation. None = no limit.\n",
    "status_nimg         = 128<<8  # Report status every N training images. None = disable.\n",
    "snapshot_nimg       = 8<<16    # Save network snapshot every N training images. None = disable.\n",
    "checkpoint_nimg     = 128<<16  # Save state checkpoint every N training images. None = disable.\n",
    "\n",
    "loss_scaling        = 1        # Loss scaling factor for reducing FP16 under/overflows.\n",
    "force_finite        = True     # Get rid of NaN/Inf gradients before feeding them to the optimizer.\n",
    "cudnn_benchmark     = True     # Enable torch.backends.cudnn.benchmark?\n",
    "device              = torch.device('cuda')\n",
    "\n",
    "if os.path.exists(f'{run_dir}/'):\n",
    "    shutil.rmtree(run_dir)\n",
    "    os.makedirs(f'{run_dir}/')\n",
    "\n",
    "# Initialize.\n",
    "prev_status_time = time.time()\n",
    "misc.set_random_seed(seed, dist.get_rank())\n",
    "# torch.backends.cudnn.benchmark = cudnn_benchmark\n",
    "torch.backends.cudnn.allow_tf32 = False\n",
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "torch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction = False\n",
    "\n",
    "# Validate batch size.\n",
    "batch_gpu_total = batch_size // dist.get_world_size()\n",
    "if batch_gpu is None or batch_gpu > batch_gpu_total:\n",
    "    batch_gpu = batch_gpu_total\n",
    "num_accumulation_rounds = batch_gpu_total // batch_gpu\n",
    "assert batch_size == batch_gpu * num_accumulation_rounds * dist.get_world_size()\n",
    "assert total_nimg % batch_size == 0\n",
    "assert slice_nimg is None or slice_nimg % batch_size == 0\n",
    "assert status_nimg is None or status_nimg % batch_size == 0\n",
    "assert snapshot_nimg is None or (snapshot_nimg % batch_size == 0 and snapshot_nimg % 1024 == 0)\n",
    "assert checkpoint_nimg is None or (checkpoint_nimg % batch_size == 0 and checkpoint_nimg % 1024 == 0)\n",
    "\n",
    "# Setup dataset, and network.\n",
    "dist.print0('Loading dataset...')\n",
    "# Pass in training dataset object.\n",
    "dataset_obj = training_dataset\n",
    "\n",
    "ref_image, ref_label = dataset_obj[0]\n",
    "dist.print0('Constructing network...')\n",
    "interface_kwargs = dict(img_resolution=ref_image.shape[-1], img_channels=ref_image.shape[1], label_dim=ref_label.shape[-1])\n",
    "# Pass in network object.\n",
    "net = net\n",
    "net.train().requires_grad_(True).to(device)\n",
    "\n",
    "# Print network summary.\n",
    "if dist.get_rank() == 0:\n",
    "    misc.print_module_summary(net, [\n",
    "        torch.zeros([batch_gpu, net.img_channels, net.temporal_resolution, net.img_resolution, net.img_resolution], device=device), # ------------------------need to alter dimensions of module summary input--------------------------------\n",
    "        torch.ones([batch_gpu], device=device),\n",
    "        torch.zeros([batch_gpu, net.label_dim], device=device),\n",
    "    ], max_nesting=2)\n",
    "\n",
    "# Setup training state.\n",
    "dist.print0('Setting up training state...')\n",
    "state = dnnlib.EasyDict(cur_nimg=0, total_elapsed_time=0)\n",
    "# ddp = torch.nn.parallel.DistributedDataParallel(net, device_ids=[device])\n",
    "# loss_fn = dnnlib.util.construct_class_by_name(**loss_kwargs)\n",
    "loss_fn = loss_fn\n",
    "optimizer = dnnlib.util.construct_class_by_name(params=net.parameters(), **optimizer_kwargs)\n",
    "ema = dnnlib.util.construct_class_by_name(net=net, **ema_kwargs) if ema_kwargs is not None else None\n",
    "\n",
    "# Load previous checkpoint and decide how long to train.\n",
    "checkpoint = dist.CheckpointIO(state=state, net=net, loss_fn=loss_fn, optimizer=optimizer, ema=ema)\n",
    "checkpoint.load_latest(run_dir)\n",
    "stop_at_nimg = total_nimg\n",
    "if slice_nimg is not None:\n",
    "    granularity = checkpoint_nimg if checkpoint_nimg is not None else snapshot_nimg if snapshot_nimg is not None else batch_size\n",
    "    slice_end_nimg = (state.cur_nimg + slice_nimg) // granularity * granularity # round down\n",
    "    stop_at_nimg = min(stop_at_nimg, slice_end_nimg)\n",
    "assert stop_at_nimg > state.cur_nimg\n",
    "dist.print0(f'Training from {state.cur_nimg // 1000} kimg to {stop_at_nimg // 1000} kimg:')\n",
    "dist.print0()\n",
    "\n",
    "# Main training loop.\n",
    "dataset_sampler = misc.InfiniteSampler(dataset=dataset_obj, rank=dist.get_rank(), num_replicas=dist.get_world_size(), seed=seed, start_idx=state.cur_nimg)\n",
    "dataset_iterator = iter(dnnlib.util.construct_class_by_name(dataset=dataset_obj, sampler=dataset_sampler, batch_size=batch_gpu, **data_loader_kwargs))\n",
    "prev_status_nimg = state.cur_nimg\n",
    "cumulative_training_time = 0\n",
    "start_nimg = state.cur_nimg\n",
    "stats_jsonl = None\n",
    "while True:\n",
    "    done = (state.cur_nimg >= stop_at_nimg)\n",
    "\n",
    "    # Report status.\n",
    "    if status_nimg is not None and (done or state.cur_nimg % status_nimg == 0) and (state.cur_nimg != start_nimg or start_nimg == 0):\n",
    "        cur_time = time.time()\n",
    "        state.total_elapsed_time += cur_time - prev_status_time\n",
    "        cur_process = psutil.Process(os.getpid())\n",
    "        cpu_memory_usage = sum(p.memory_info().rss for p in [cur_process] + cur_process.children(recursive=True))\n",
    "        dist.print0(' '.join(['Status:',\n",
    "            'kimg',         f\"{training_stats.report0('Progress/kimg',                              state.cur_nimg / 1e3):<9.1f}\",\n",
    "            'time',         f\"{dnnlib.util.format_time(training_stats.report0('Timing/total_sec',   state.total_elapsed_time)):<12s}\",\n",
    "            'sec/tick',     f\"{training_stats.report0('Timing/sec_per_tick',                        cur_time - prev_status_time):<8.2f}\",\n",
    "            'sec/kimg',     f\"{training_stats.report0('Timing/sec_per_kimg',                        cumulative_training_time / max(state.cur_nimg - prev_status_nimg, 1) * 1e3):<7.3f}\",\n",
    "            'maintenance',  f\"{training_stats.report0('Timing/maintenance_sec',                     cur_time - prev_status_time - cumulative_training_time):<7.2f}\",\n",
    "            'cpumem',       f\"{training_stats.report0('Resources/cpu_mem_gb',                       cpu_memory_usage / 2**30):<6.2f}\",\n",
    "            'gpumem',       f\"{training_stats.report0('Resources/peak_gpu_mem_gb',                  torch.cuda.max_memory_allocated(device) / 2**30):<6.2f}\",\n",
    "            'reserved',     f\"{training_stats.report0('Resources/peak_gpu_mem_reserved_gb',         torch.cuda.max_memory_reserved(device) / 2**30):<6.2f}\",\n",
    "        ]))\n",
    "        cumulative_training_time = 0\n",
    "        prev_status_nimg = state.cur_nimg\n",
    "        prev_status_time = cur_time\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "        # Flush training stats.\n",
    "        training_stats.default_collector.update()\n",
    "        if dist.get_rank() == 0:\n",
    "            if stats_jsonl is None:\n",
    "                stats_jsonl = open(os.path.join(run_dir, 'stats.jsonl'), 'at')\n",
    "            fmt = {'Progress/tick': '%.0f', 'Progress/kimg': '%.3f', 'timestamp': '%.3f'}\n",
    "            items = [(name, value.mean) for name, value in training_stats.default_collector.as_dict().items()] + [('timestamp', time.time())]\n",
    "            items = [f'\"{name}\": ' + (fmt.get(name, '%g') % value if np.isfinite(value) else 'NaN') for name, value in items]\n",
    "            stats_jsonl.write('{' + ', '.join(items) + '}\\n')\n",
    "            stats_jsonl.flush()\n",
    "\n",
    "        # Update progress and check for abort.\n",
    "        dist.update_progress(state.cur_nimg // 1000, stop_at_nimg // 1000)\n",
    "        if state.cur_nimg == stop_at_nimg and state.cur_nimg < total_nimg:\n",
    "            dist.request_suspend()\n",
    "        if dist.should_stop() or dist.should_suspend():\n",
    "            done = True\n",
    "            \n",
    "        # Validate.\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            noise = torch.randn([1, net.img_channels, net.temporal_resolution, net.img_resolution, net.img_resolution], device=device)\n",
    "            labels = torch.eye(net.label_dim, device=device)[torch.randint(net.label_dim, size=[1], device=device)]\n",
    "            samples = edm_sampler(net, noise, labels=labels, num_steps=32, sigma_min=0.002, sigma_max=80, rho=7, guidance=1,\n",
    "                        S_churn=0, S_min=0, S_max=float('inf'), S_noise=1, dtype=torch.float32, randn_like=torch.randn_like)\n",
    "            np.save(f'{run_dir}/samples_{str(state.cur_nimg//1024).zfill(6)}.npy', samples.detach().cpu().numpy())\n",
    "            net.train()\n",
    "            \n",
    "\n",
    "    # Save network snapshot.\n",
    "    if snapshot_nimg is not None and state.cur_nimg % snapshot_nimg == 0 and (state.cur_nimg != start_nimg or start_nimg == 0) and dist.get_rank() == 0:\n",
    "        ema_list = ema.get() if ema is not None else optimizer.get_ema(net) if hasattr(optimizer, 'get_ema') else net\n",
    "        ema_list = ema_list if isinstance(ema_list, list) else [(ema_list, '')]\n",
    "        for ema_net, ema_suffix in ema_list:\n",
    "            data = dnnlib.EasyDict(dataset_kwargs=dataset_kwargs, loss_fn=loss_fn)\n",
    "            data.ema = copy.deepcopy(ema_net).cpu().eval().requires_grad_(False).to(torch.float16)\n",
    "            fname = f'network-snapshot-{state.cur_nimg//1000:07d}{ema_suffix}.pkl'\n",
    "            dist.print0(f'Saving {fname} ... ', end='', flush=True)\n",
    "            with open(os.path.join(run_dir, fname), 'wb') as f:\n",
    "                pickle.dump(data, f)\n",
    "            dist.print0('done')\n",
    "            del data # conserve memory\n",
    "\n",
    "    # Save state checkpoint.\n",
    "    if checkpoint_nimg is not None and (done or state.cur_nimg % checkpoint_nimg == 0) and state.cur_nimg != start_nimg:\n",
    "        checkpoint.save(os.path.join(run_dir, f'training-state-{state.cur_nimg//1000:07d}.pt'))\n",
    "        misc.check_ddp_consistency(net)\n",
    "\n",
    "    # Done?\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "    # Evaluate loss and accumulate gradients.\n",
    "    batch_start_time = time.time()\n",
    "    misc.set_random_seed(seed, dist.get_rank(), state.cur_nimg)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    iteration_losses = []\n",
    "\n",
    "    for round_idx in range(num_accumulation_rounds):\n",
    "        # with misc.ddp_sync(ddp, (round_idx == num_accumulation_rounds - 1)):\n",
    "        images, labels = next(dataset_iterator)\n",
    "        images = images.to(device)\n",
    "        # loss = loss_fn(net=ddp, images=images, labels=labels.to(device))\n",
    "        loss = loss_fn(net=net, images=images, labels=labels.to(device))\n",
    "\n",
    "        # record the loss value\n",
    "        iteration_losses.append(loss)\n",
    "\n",
    "        training_stats.report('Loss/loss', loss)\n",
    "        loss.sum().mul(loss_scaling / batch_gpu_total).backward()\n",
    "\n",
    "    # Run optimizer and update weights.\n",
    "    lr = dnnlib.util.call_func_by_name(cur_nimg=state.cur_nimg, batch_size=batch_size, **lr_kwargs)\n",
    "    training_stats.report('Loss/learning_rate', lr)\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = lr\n",
    "    if force_finite:\n",
    "        for param in net.parameters():\n",
    "            if param.grad is not None:\n",
    "                torch.nan_to_num(param.grad, nan=0, posinf=0, neginf=0, out=param.grad)\n",
    "    optimizer.step()\n",
    "\n",
    "    # Update EMA and training state.\n",
    "    state.cur_nimg += batch_size\n",
    "    if ema is not None:\n",
    "        ema.update(cur_nimg=state.cur_nimg, batch_size=batch_size)\n",
    "    cumulative_training_time += time.time() - batch_start_time\n",
    "#----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss history\n",
    "plt.figure(figsize = (10, 5))\n",
    "plt.plot(iteration_losses, label = 'Iteration Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n",
    "sample = np.load('/home/trevor/repos/video_edm2/experiments/mnist_test/samples_027904_99339602063455575688133065481878134393250160843453077890448214290674994981349861913707152312216145464973274376175502395242759439.npy')\n",
    "sample.shape\n",
    "plt.imshow(sample[0,0,:,:,8])\n",
    "import mrcfile\n",
    "mrcfile.write('/home/trevor/repos/video_edm2/experiments/mnist_test/samples_027904_99339602.mrc', sample[:8,0], overwrite=True)\n",
    "integers = torch.randint(10, size=[5], device=torch.device('cuda'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SuperResolution_CT_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
